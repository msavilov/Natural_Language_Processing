{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4091a1f2",
   "metadata": {},
   "source": [
    "### Описание задания.\n",
    "\n",
    "#### Часть 1: Составление словарей для классификации по тональности.\n",
    "\n",
    "При классификации текстов или предложений по тональности необходимо использовать оценочные словари для предметной области, то есть, такие словари, в которых содержатся отрицательные и позитивные слова для какой-то предметной области. Идея подобных словарей основана на следующих наблюдениях: во-первых, для разных товаров используются разные оценочные слова (например бывает “захватывающая книга”, но не бывает “захватывающих лыж”), во-вторых, в контексте разных товаров одни и те же слова могут иметь разную окраску (слово “тормоз” в отзыве на велосипед имеет нейтральную окраску, в отзыве на компьютер – резко негативную, “пыль” в контексте пылесосов – нейтральную, в контексте кофемолок – положительную (“мелкий помол в пыль”)). Еще один пример: \"теплое пиво\" – это плохо, а \"теплый свитер\" – это хорошо.\n",
    "\n",
    "Данные для задания: датасет отзывов на банки с сайта banki.ru. Данные содержат непосредственно тексты отзывов, некоторую дополнительную информацию, а также оценку по шкале от 1 до 5. Тексты хранятся в json-ах в массиве responses.\n",
    "\n",
    "- Разбить всю коллекцию отзывов на предложения. Лемматизировать все слова.\n",
    "- Обучить по коллекции предложений word2vec.\n",
    "- Привести несколько удачных и неудачных примеров решения стандартных текстов для word2vec:\n",
    "    - тест на определение ближайших слов\n",
    "    - тест на аналогии (мужчина – король : женщина – королева)\n",
    "    - тест на определение лишнего слова.\n",
    "\n",
    "- Построить несколько визуализаций:\n",
    "    - TSNE для топ-100 (или топ-500) слов и найдти осмысленные кластеры слов\n",
    "    - задать координаты для нового пространства следующим образом: одна ось описывает отношение \"плохо – хорошо\", вторая – \"медленно – быстро\" и найдите координаты названий банков в этих координатах. Более формально: берем вектор слова \"хорошо\", вычитаем из него вектор слова \"плохо\", получаем новый вектор, который описывает разницу между хорошими и плохими словами. Берем вектор слова \"сбербанк\" и умножаем его на этот новый вектор – получаем координату по первой оси. Аналогично – для второй оси. Две координаты уже можно нарисовать на плоскости.\n",
    "\n",
    "\n",
    "#### Часть 2:  Распространение метки.\n",
    "\n",
    "Определить 5-8 позитивных слов (например, “быстрый”, “удобный”) и 5-8 негативных слов (например,“очередь”, “медленно”). Эти слова будут основной будущего оценочного словаря. Пусть позитивному классу соответствует метка 1, негативному – -1. Пометьте выбранные слова в лексическом графе соответствующими метками. Запустить любой известный вам метод распространения метки (Label Propogation) в лексическом графе. На выходе метода распространения ошибки должны быть новые слова, помеченные метками 1 и -1 – это и есть искомые оценочные слова.\n",
    "\n",
    "Алгоритмы распространения метки устроены примерно так: пусть мы находимся в выршине, помеченном +1. С какой-то вероятностью мы переносим эту метку на соседние узлы. С меньшей вероятностью переносим ее на вершины на расстоянии два. В конце распространения метки, часть вершин оказывается помечена меткой +1, часть – -1, большая часть остается без метки.\n",
    "\n",
    "Рекомендуемые алгоритмы распространения метки:\n",
    "- graphlab.label_propagation (graphlab доступен бесплатно по образовательной лицензии)\n",
    "- sklearn.semi_supervised.LabelPropagation\n",
    "- sklearn.semi_supervised.LabelSpreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a580f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "008989d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import igraph as ig\n",
    "import gdown\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymorphy2\n",
    "import re\n",
    "import regex\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from scipy import sparse\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim import similarities\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import lsimodel, TfidfModel\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.metrics  import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13827e6e",
   "metadata": {},
   "source": [
    "#### Необходимые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96da656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystopwords = stopwords.words('russian')\n",
    "\n",
    "ru_words = re.compile(\"[А-Яа-я]+\")\n",
    "\n",
    "def get_top_word(bow, count_word = 10):\n",
    "    '''\n",
    "    Принимает на вход результат TfidfVectorizer.fit_transform.\n",
    "    Возвращает список ключевых слов\n",
    "    '''\n",
    "    idx = np.ravel(bow.sum(axis=0).argsort(axis=1))[::-1][:count_word]\n",
    "    top_words = np.array(vec.get_feature_names_out())[idx].tolist()\n",
    "    return top_words\n",
    "\n",
    "\n",
    "def words_only(text):\n",
    "    return \" \".join(ru_words.findall(text))\n",
    "\n",
    "def lemmatize(text):\n",
    "    try:\n",
    "        return  \" \".join([morph.parse(word)[0].normal_form for word in text.lower().split()])\n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "def remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return \"\"\n",
    " \n",
    "def preprocess(text):\n",
    "    return remove_stopwords(lemmatize(words_only(text.lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b9a783",
   "metadata": {},
   "source": [
    "#### Скачивание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3074aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1OelGGXPXBinXvZnDb1Bmmxe4rtdBmqdk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7a8163d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'banki_responses.json.bz2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdown.download(url, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c88137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201030it [02:21, 1421.52it/s]\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "with bz2.BZ2File('banki_responses.json.bz2', 'r') as thefile:\n",
    "    for row in tqdm(thefile):\n",
    "        resp = json.loads(row)\n",
    "        if not resp['rating_not_checked'] and (len(resp['text'].split()) > 0):\n",
    "            responses.append(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebadbef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153499"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3b76afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>rating_not_checked</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>bank_license</th>\n",
       "      <th>author</th>\n",
       "      <th>bank_name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>г. Москва</td>\n",
       "      <td>False</td>\n",
       "      <td>Жалоба</td>\n",
       "      <td>0</td>\n",
       "      <td>лицензия № 2562</td>\n",
       "      <td>uhnov1</td>\n",
       "      <td>Бинбанк</td>\n",
       "      <td>2015-06-08 12:50:54</td>\n",
       "      <td>Добрый день! Я не являюсь клиентом банка и пор...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>г. Новосибирск</td>\n",
       "      <td>False</td>\n",
       "      <td>Не могу пользоваться услугой Сбербанк он-лайн</td>\n",
       "      <td>0</td>\n",
       "      <td>лицензия № 1481</td>\n",
       "      <td>Foryou</td>\n",
       "      <td>Сбербанк России</td>\n",
       "      <td>2015-06-08 11:09:57</td>\n",
       "      <td>Доброго дня! Являюсь держателем зарплатной кар...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>г. Москва</td>\n",
       "      <td>False</td>\n",
       "      <td>Двойное списание за один товар.</td>\n",
       "      <td>1</td>\n",
       "      <td>лицензия № 2562</td>\n",
       "      <td>Vladimir84</td>\n",
       "      <td>Бинбанк</td>\n",
       "      <td>2015-06-05 20:14:28</td>\n",
       "      <td>Здравствуйте!  Дублирую свое заявление от 03.0...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>г. Ставрополь</td>\n",
       "      <td>False</td>\n",
       "      <td>Меняют проценты комиссии  не предупредив и не ...</td>\n",
       "      <td>2</td>\n",
       "      <td>лицензия № 1481</td>\n",
       "      <td>643609</td>\n",
       "      <td>Сбербанк России</td>\n",
       "      <td>2015-06-05 13:51:01</td>\n",
       "      <td>Добрый день!! Я открыл расчетный счет в СберБа...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>г. Челябинск</td>\n",
       "      <td>False</td>\n",
       "      <td>Верните денежные средства за страховку</td>\n",
       "      <td>1</td>\n",
       "      <td>лицензия № 2766</td>\n",
       "      <td>anfisa-2003</td>\n",
       "      <td>ОТП Банк</td>\n",
       "      <td>2015-06-05 10:58:12</td>\n",
       "      <td>04.03.2015 г. взяла кредит в вашем банке, заяв...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  rating_not_checked  \\\n",
       "0       г. Москва               False   \n",
       "1  г. Новосибирск               False   \n",
       "2       г. Москва               False   \n",
       "3   г. Ставрополь               False   \n",
       "4    г. Челябинск               False   \n",
       "\n",
       "                                               title  num_comments  \\\n",
       "0                                             Жалоба             0   \n",
       "1      Не могу пользоваться услугой Сбербанк он-лайн             0   \n",
       "2                    Двойное списание за один товар.             1   \n",
       "3  Меняют проценты комиссии  не предупредив и не ...             2   \n",
       "4             Верните денежные средства за страховку             1   \n",
       "\n",
       "      bank_license       author        bank_name             datetime  \\\n",
       "0  лицензия № 2562       uhnov1          Бинбанк  2015-06-08 12:50:54   \n",
       "1  лицензия № 1481       Foryou  Сбербанк России  2015-06-08 11:09:57   \n",
       "2  лицензия № 2562   Vladimir84          Бинбанк  2015-06-05 20:14:28   \n",
       "3  лицензия № 1481       643609  Сбербанк России  2015-06-05 13:51:01   \n",
       "4  лицензия № 2766  anfisa-2003         ОТП Банк  2015-06-05 10:58:12   \n",
       "\n",
       "                                                text  rating_grade  \n",
       "0  Добрый день! Я не являюсь клиентом банка и пор...           NaN  \n",
       "1  Доброго дня! Являюсь держателем зарплатной кар...           NaN  \n",
       "2  Здравствуйте!  Дублирую свое заявление от 03.0...           NaN  \n",
       "3  Добрый день!! Я открыл расчетный счет в СберБа...           NaN  \n",
       "4  04.03.2015 г. взяла кредит в вашем банке, заяв...           NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(responses)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ddb53",
   "metadata": {},
   "source": [
    "### Часть 1: Составление словарей для классификации по тональности.\n",
    "#### Разбить всю коллекцию отзывов на предложения. Лемматизировать все слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c20ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in range(len(df)):\n",
    "    sentences.extend(sent_tokenize(df.text.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5f57b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Добрый день!',\n",
       " 'Я не являюсь клиентом банка и поручителем по кредитному договору, а также не являюсь каким-либо другим лицом, письменно  оформившим отношения с банком по поводу урегулирования чьей-либо  задолженности.',\n",
       " 'Начиная с марта 2015 года начали приходить бесконечные письма из ООО \"Примо коллект\"на мой адрес: город Москва, Уваровский переулок, дом 10, квартира 111, с угрозами о возбуждении уголовного дела в отношении гражданина Филиппова Эдуарда Владимировича, который уклоняется от уплаты взятых им кредитов: договор № 81014 от 20.10.2013 года и договор № 2464946 от 09.10.2014 года.',\n",
       " 'Со всей ответственностью\\xa0 хочу Вас заверить, что вышеуказанный гражданин, которого Вы разыскиваете, мне не знаком и никогда в моем адресе не был зарегистрирован.',\n",
       " 'Каким образом Вы не удостоверившись в подлинности его документов оформили на его имя кредитный договор, мне по меньшей мере не понятно,\\xa0 и почему по Вашей милости я должна переживать и бояться за себе и свое имущество.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf75bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890937c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemma[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39170b9",
   "metadata": {},
   "source": [
    "#### Обучение по коллекции предложений word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00915d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model_response = Word2Vec(lemma, workers=4, vector_size=300, min_count=3, window=5, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332de751",
   "metadata": {},
   "source": [
    "#### Привести несколько удачных и неудачных примеров решения стандартных текстов для word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response.most_similar('банк')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response.most_similar(positive=['вклад', 'долг'], negative=['доход'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd639f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response.doesnt_match('вклад прибыль доход рост кредит'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_ru.similarity('вклад', 'кредит'))\n",
    "print(model_ru.similarity('процент', 'кредит'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ig.Graph(directed=True)\n",
    "for word in model.wv.vocab.keys():\n",
    "    g.add_vertex(word)\n",
    "    \n",
    "    \n",
    "    \n",
    "for word in model.wv.vocab.keys() :\n",
    "    node = g.vs.select(name = word).indices[0]\n",
    "    similar_words = model.most_similar(word, topn=5)\n",
    "    for sim in similar_words:\n",
    "        word1 = sim[0]\n",
    "        val  = sim[1]\n",
    "        new_node = g.vs.select(name = word1).indices[0]\n",
    "        g.add_edge(node, new_node, weight = val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
